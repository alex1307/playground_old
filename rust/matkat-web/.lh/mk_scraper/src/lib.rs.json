{
    "sourceFile": "mk_scraper/src/lib.rs",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 1,
            "patches": [
                {
                    "date": 1641984802307,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1641984809543,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,5 +1,5 @@\n-\n+pub mod cambridge_scraper;\n pub mod collins_scraper;\n pub mod oxford_scraper;\n pub mod unit_tests;\n pub mod constants;\n"
                }
            ],
            "date": 1641984802307,
            "name": "Commit-0",
            "content": "\npub mod collins_scraper;\npub mod oxford_scraper;\npub mod unit_tests;\npub mod constants;\npub mod model;\npub mod task_executor;\n\nuse std::io::Cursor;\n\n\nuse common_libs::{error::{ServiceExuctionResult, ServiceError, ServiceErrorType, DictionaryError, DictionaryErrorKind}, files::read_file_content, utils::{trim_tabs, replace_tabs}};\nuse constants::{USER_AGENT, INVALID, MP3_EXT};\nuse itertools::Itertools;\nuse log::{debug, error, info};\nuse model::{DictionaryEntry, Dictionary};\nuse reqwest::StatusCode;\nuse scraper::{Html, Selector};\n\nuse futures::future::join_all;\nuse crate::constants::NOT_FOUND;\n\n\npub fn wget(url: &str, file_name: &str) -> ServiceExuctionResult<String> {\n    let status = std::process::Command::new(\"wget\")\n    .arg(\"--user-agent\")\n    .arg(USER_AGENT)\n    .arg(url)\n    .arg(\"-O\")\n    .arg(file_name)\n    .status();\n\n    if status.is_err() {\n        error!(\"failed.executing.wget: {}\", status.err().unwrap());\n        return Err(ServiceError {\n            message: \"wget.failed\".to_string(),\n            error_type: ServiceErrorType::Failure,\n        });\n    }\n\n    let bytes = read_file_content(file_name)?;\n    Ok(String::from_utf8(bytes)?)\n}\n\npub async fn fetch_url(url: String, file_name: String) -> ServiceExuctionResult<()> {\n    debug!(\"downloading from [{}] to {}\", url, file_name);\n    let response = reqwest::get(url.clone()).await.unwrap();\n    let status = response.status();\n    info!(\"download status: {}\", status);\n    if status.is_success() {\n        let mut file = std::fs::File::create(file_name.clone())?;\n        let mut content = Cursor::new(response.bytes().await?);\n        std::io::copy(&mut content, &mut file)?;\n        Ok(())\n    } else {\n        match wget(&url, &file_name) {\n            Ok(_) => Ok(()),\n            Err(err) => Err(err)\n        }\n    }\n    \n}\n\nasync fn download_from_url(url: &str) -> ServiceExuctionResult<String> {\n    println!(\"URL: {}\", url.clone());\n    let response = reqwest::get(url).await?;\n    println!(\"resposne: {:?}\", response);\n    if StatusCode::OK != response.status() {\n        let msg = format!(\"nok.status.code: {}\", response.status().as_str());\n        return Err(ServiceError {\n            message: msg,\n            error_type: ServiceErrorType::Unavailable,\n        });\n    }\n\n    let bytes = response.bytes().await.unwrap();\n    let slice = &bytes[..];\n    let content = String::from_utf8(Vec::from(slice)).unwrap();\n    let lower = content.to_lowercase();\n    for i in 0..NOT_FOUND.len() {\n        if lower.contains(NOT_FOUND[i]) {\n            return Err(ServiceError {\n                message: \"not.found\".to_string(),\n                error_type: ServiceErrorType::ResourceNotFound,\n            });\n        }\n    }\n    Ok(content)\n}\n\nfn description(inner_html: String) -> Option<String> {\n    let mut replaced = match inner_text(inner_html.clone(), \"a\") {\n        Ok(inner) => inner,\n        Err(_err) => return None,\n    };\n\n    replaced = match inner_text(replaced, \"span\") {\n        Ok(inner) => inner,\n        Err(_) => return None,\n    };\n\n    replaced = replaced.replace(\"\\n\", \" \");\n    replaced = trim_tabs(&mut replaced);\n    replaced = replaced.replace(\" .\", \".\");\n    Some(replaced)\n}\n\nfn inner_text(inner_html: String, tag: &str) -> Result<String, DictionaryError> {\n    let mut replaced = inner_html.clone();\n    let mut open_tag = String::from(\"<\");\n    open_tag.push_str(tag);\n    let mut close_tag = String::from(\"</\");\n    close_tag.push_str(tag);\n    close_tag.push_str(\">\");\n\n    if !(inner_html.contains(&open_tag) && inner_html.contains(&close_tag)) {\n        return Ok(inner_html);\n    }\n\n    let tag_selector = Selector::parse(tag).unwrap();\n\n    while replaced.contains(&open_tag) && replaced.contains(&close_tag) {\n        let start = replaced.find(&open_tag).unwrap();\n        let end = replaced.find(&close_tag).unwrap();\n        if start < end + close_tag.len() {\n            let to_be_replaced = &replaced[start..end + close_tag.len()];\n            let a_href = Html::parse_fragment(&replaced);\n            let inner = a_href.select(&tag_selector).next().unwrap().inner_html();\n            replaced = replaced.replace(to_be_replaced, &inner);\n        } else {\n            error!(\n                \"parse.error: start postion {} is bofore end: {}\",\n                start,\n                end + close_tag.len()\n            );\n            return Err(DictionaryError::throw(\n                \"unable.to.parse.definition\",\n                DictionaryErrorKind::InvalidData,\n            ));\n        }\n    }\n    Ok(replaced)\n}\n\nfn elements(query: &str, html_content: &str, inner: bool) -> Vec<String> {\n    let fragment = Html::parse_fragment(&html_content);\n    let selector = Selector::parse(query).unwrap();\n    let elements = fragment.select(&selector).into_iter();\n    let mut all = Vec::new();\n    for e in elements {\n        if inner {\n            all.push(e.inner_html());\n        } else {\n            all.push(e.html());\n        }\n    }\n    all\n}\n\nfn first_element(query: &str, html_content: &str, inner: bool) -> Option<String> {\n    let fragment = Html::parse_fragment(&html_content);\n    let selector = Selector::parse(query).unwrap();\n    let mut elements = fragment.select(&selector).into_iter();\n    let found = elements.next();\n\n    if found.is_some() {\n        return if inner {\n            Some(found.unwrap().inner_html())\n        } else {\n            Some(found.unwrap().html())\n        };\n    }\n\n    None\n}\n\nfn mp3_element(mp3_query: &str, html_content: &str) -> Option<String> {\n    first_element(mp3_query, html_content, false)\n}\n\npub async fn merge_definitions(url1: &str, url2: &str, url3: &str) -> Option<DictionaryEntry> {\n    let source_1 = oxford_scraper::download(url1).await;\n    let source_2 = oxford_scraper::download(url2).await;\n\n    if source_1.is_err() {\n        return None;\n    }\n\n    if source_2.is_err() {\n        return None;\n    }\n\n    let mut merged = source_1.unwrap();\n    for def in source_2.unwrap().definitions {\n        merged.definitions.push(def);\n    }\n    if !url3.is_empty() {\n        let source_3 = oxford_scraper::download(url3).await;\n        if source_3.is_ok() {\n            for def in source_3.unwrap().definitions {\n                merged.definitions.push(def);\n            }\n        }\n    }\n\n    Some(merged)\n}\n\nfn to_url(base_url: &str, word: &str) -> String {\n    if word.is_empty() {\n        return INVALID.to_lowercase();\n    }\n\n    if base_url.is_empty() {\n        return INVALID.to_lowercase();\n    }\n    let mut w = String::from(word);\n    let mut trimmed = trim_tabs(&mut w);\n    let processed = replace_tabs(&mut trimmed, \"-\");\n    let mut url = String::from(base_url);\n    url.push_str(&processed);\n    url.to_lowercase()\n}\n\nfn mp3_element_to_url(source: &str, start_with: &str) -> Option<String> {\n    element_to_url(source, start_with, MP3_EXT)\n}\n\nfn element_to_url(source: &str, start_with: &str, end_with: &str) -> Option<String> {\n    let values: Vec<&str> = source.split_whitespace().collect();\n    let found = values\n        .into_iter()\n        .find_or_first(|s| s.contains(start_with) && s.contains(end_with));\n\n    let raw_element = if found.is_some() {\n        found.unwrap()\n    } else {\n        return None;\n    };\n\n    let start = raw_element.find(start_with).unwrap();\n    let end = raw_element.find(end_with).unwrap() + end_with.len();\n    Some(raw_element[start..end].to_lowercase())\n}\n\npub async fn scrape_it_from<S: AsRef<str>>(dictionary: String, word: S) -> Option<DictionaryEntry> {\n    match Dictionary::from(dictionary) {\n        Dictionary::Cambridge => cambridge_scraper::scrape(word.as_ref()).await,\n        Dictionary::Collins => collins_scraper::scrape(word.as_ref()).await,\n        Dictionary::Oxford => oxford_scraper::scrape(word.as_ref()).await,\n        _ => return None,\n    }\n}\n\npub  async fn scrape_all<S: AsRef<str>>(source: Vec<String>) {\n    let mut tasks = vec![];\n    for w in source {\n        let f1 = scrape_it_from(\"Cambridge\".to_lowercase(), w.clone());\n        let f2 = scrape_it_from(\"Collins\".to_lowercase(), w.clone());\n        let f3 = scrape_it_from(\"Oxford\".to_lowercase(), w.clone());\n        tasks.push(f1);\n        tasks.push(f2);\n        tasks.push(f3);\n    }    \n    let _ = join_all(tasks);    \n}"
        }
    ]
}